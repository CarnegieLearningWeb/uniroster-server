# OneImporter - Uniroster Database Population Tool

Run regularly to pull orgs/courses/classes/users/enrollments from LDAP and K12db, create and populate Uniroster tenant schemas for each district.  Where we don't have a tenantid, we try to use the Oracle party number for the district.  Failing that, we treat a school as a standalone district with the uuid as the tenantid.

## Required

### School-to-District map

For schools that have no tenant id, we'll try to use the district party number to keep districts together. We need a map, the `all_schools.csv` generated by Splunk from an Oracle query.  Run the query at https://splunk.carnegielearning.com/en-US/app/search/report?s=%2FservicesNS%2Fnobody%2Fsearch%2Fsaved%2Fsearches%2Fget_all_schools&sid=_bWdsb3ZlckBjYXJuZWdpZWxlYXJuaW5nLmNvbQ_bWdsb3ZlckBjYXJuZWdpZWxlYXJuaW5nLmNvbQ__search__RMD5deab73271702bdea_at_1604934806_12191&display.page.search.mode=fast&dispatch.sample_ratio=1&earliest=%40d&latest=now and export the results as all_schools.csv in this working directory.  The Makefile has a `make all_schools.csv` target that returns this url.

### AWS Profiles

If necessary, edit `Makefile` to update your AWS profile names.

    QA_PROFILE := qa
    PROD_PROFILE := prod

## Databases

The QA and Production uniroster databases do not allow access from the VPN, so for local testing against those database you'll need to use a server in those VPCs as a jump host if you need to access them.  I use a ssh tunnel:

    ssh -NL 3306:prod-uniroster...amazonaws.com:3306 username@jumphost

We could add an empty local mysql container for the oneroster database and build a local composefile for testing, but we'll still need the k12 database and LDAP unless we want to create containerized test versions of each.

## Development Environment

Set up a python virtual environment, don't futz with your system python.  On a Mac, I always install pyenv and pyenv-virtualenv from Homebrew on my systems.  Create a venv, install pipenv in it, and install the modules necessary for the application.

    # create the virtual environment
    pyenv virtualenv oneimporter

    # set it as the virtual environment for this working directory
    pyenv local oneimporter

    # install pipenv to the venv using pip
    pip install pipenv

    # install the other python modules listed in the Pipfile
    pipenv sync

## Environment Variables

The application will use a .env file if present and a `sample.env` is provided. `make get-environments` will fetch envvar files from Vault:

    vault kv get --field=.env secret/internal/apps/uniroster/envs/qa > qa.env
    vault kv get --field=.env secret/internal/apps/uniroster/envs/prod > prod.env

Use `make put-environments` to copy your envvar files back to Vault.  Note that Vault keeps earlier versions of secrets, so this is non-destructive.

## Building

`make build-dev` will create a container image for local testing. `make build VERSION=1.2.3` will build a tagged production-ready container.

## Testing

A pytest framework is used to ensure that the application passes all tests on every build. No actual tests are being done during that process yet hashtag todo hashtag continuous improvement hashtag devops.

`make shell` will build a dev container and launch it, placing you at the command line.  You can run a specific command in the test container with `make shell CMD="-c ls"`. That execute `bash ${CMD}`.  If your CMD is a binary rather than a shell script, you need the `-c` so that bash will try to execute the binary.

`make runtask-qa` and `make runtask-prod` will launch a one-shot run of the task at AWS ECS.

## Deployment Configurations

`make oneimporter.prod.yml` and `make oneimporter.qa.yml` will use the the qa.env and prod.env files as well as `docker-compose.yml` to create composefiles for each environment.

`make register-qa` and `make register-prod` will use the composefiles to register new task definitions at AWS ECS.

## Scheduling

A Cloudwatch rule launches a lambda to run the task automatically. `make scheduletasks` will show the steps necessary to set it up from scratch using the templates in `/scheduler`.
